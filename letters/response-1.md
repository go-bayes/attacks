October 13, 2022 

Title: "Long-term causal effect of radical white terrorism" 
Tracking #: PNASNEXUS-2022-00743 
Authors: Bulbulia et al. 

Dear Professor Bulbulia, 

The expert who is serving as editor for your manuscript [MS# PNASNEXUS-2022-00743] has obtained 3 reviews, which are included below. The editor requests that you constructively address the concerns of the reviewers in a revised manuscript. Please note that multiple revisions are rarely permitted and there is no guarantee that the paper will be accepted. 

PNAS Nexus allows 60 days to submit a revision. Your revision is due by December 12, 2022. If you require additional time, please contact the PNAS Nexus office. 

When submitting revised materials, we require that you include a cover letter with a point-by-point response to the reviewers' comments, and a file with the changes highlighted. If you submitted a single PDF at initial submission, you must submit individual publication-ready files (e.g., Word file for manuscript text; EPS, TIFF, or high-resolution PDF for figures; Word file for tables; etc.) 

Please note that statements such as "data not shown" and "personal communication" cannot be used to support claims in the work and should be removed prior to submission. Authors are encouraged to use supplementary material to show all necessary data, or to deposit their data in a publicly accessible database if posting as supplementary material is not possible. Authors should include a statement in their methods section describing how readers will be able to access the data, associated protocols, code, and materials. 

You may submit your revised manuscript here: https://pnasnexus.msubmit.net/cgi-bin/main.plex?el=A7QV6EDJx7A1EBjb5I3A9ftdToRQnEtN9eMxyuF6drS1QZ. 

***Adding, removing, or reordering your author list requires approval from all coauthors before we can proceed. If you wish to add an additional corresponding author, please note this in the "Comments for Editorial Staff" box when completing your revision.*** 

We recommend that authors use ORCID IDs. If you provide your ORCID when you submit your manuscript, you can opt in to have your ORCID record automatically updated if your article is published. For proper authentication, authors must provide their ORCID at submission and are not permitted to add ORCIDs on proofs. Watch for an email from Crossref in your ORCID inbox requesting permission to access your ORCID record. 

Thank you for submitting to PNAS Nexus. We look forward to receiving your revision. 

Yours, 
Yannis C. Yortsos 
PNAS Nexus Interim Editor-in-Chief 


# 

Dear Dr Yortsos & Colleagues

Below we describe how we have addressed questions and concerns raised during review of our manuscript.  Doing so has resulted in a stronger manuscript. We are therefore grateful to you, the Associate Editor and the three anonymous referees.  

Our responses are in **bold**. 

# 

********************* 
Associate Editor Comments: 

I, along with the three reviewers, commend your work on this important question, bringing attention to the question of causality and attempting to apply a couple of different methods to assess the impact of the terrorist attack on attitudes. Because we believe in the paper's potential, we encourage careful revisions with regards to the following areas: 

1. More attention needs to be paid to theoretical expectations. Through which mechanism(s) do we expect the attack to influence attitudes? Which attitudes, specifically? And who is expected to be most affected? You'll see that answers to the last two questions may help you address items (2) and (3) below. 


**We have clarified that our main interest is in whether the boost to Muslim acceptance following the attacks persists or regresses to a mean. Our original manuscript focussed on the marginal effect of the attacks. In the revised manuscript, we examine effect-modification of the attacks by levels of political identification.**



2. Both Reviewers #1 and #3 suggest looking at additional attitudes, either as alternative outcomes or look for placebo effects. I would encourage you to explore both, but the latter warrants particular attention. Depending on your theory (see (1)), you may expect the effect to spill-over to attitudes towards other groups. Alternatively, you may expect that only attitudes towards Muslims will be affected. Either way, you should find an attitude (or set of attitudes) that you think will not be affected and use these to test for a placebo effect. 


**Potential negative controls in the NZAVS are as follows (1) warmth toward those with mental illness (introduced in Time 9); (2) warmth toward elderly people (Time 9); warmth toward Overweight people (Time 1). A new appendix tests whether the attacks affected acceptance in these outcomes, and reports no evidence for such effects.*** 

3. Reviewer #2 raises critical questions about your application of the imputation method to this particular case, where the entire population is treated. They are skeptical that you will be able to take population-wide confounders into account but want to remain open-minded, and I encourage you to take their concerns to heart. Although not directly related to the methodology -- more to the conclusions that we may draw from your results -- but you should also consider the question raised by Reviewer #1. Your treatment may in fact be a "bundle" -- not just the attack itself, but also a host of reactions to it. You may be unable to identify what exactly is doing the work here, but you need to at least acknowledge the realities of this particular treatment (and others like it). 

**Attack bundle: it is a good point. We have included the following statement in our conclusions " ..."  Confounding: Because the attacks were random, we do not have confounding for the effect of A on Y. The problem here is model misspecification for the imputations, particularly for the counterfactual contrast.  We have included the following statement in our conclusions. **


4. Finally, I encourage you to take Reviewer #1's suggestion to consider the effect of COVID-19 more seriously in your analysis and discussion. As population-wide treatments go, it's a pretty significant one. 


**We have included the following statement: "xxx" **


We look forward to seeing the revised manuscript. 


Reviewer #1 Comments for the Author: 

In order to identify a long-term causal effect of a terrorist attack on attitudes toward Muslims the authors analyzed data from the longitudinal panel from New Zealand. They concluded that the attack boosted acceptance of Muslims and that the observed growth in positive attitudes after the attack was similar to what could be expected if the attack had not occurred. Given the available data authors suggest that the positive effect of the attack was durable for at least two years. The main theoretical contribution according to the authors addresses the question of the long-term (vs. transitory) psychological effects of terrorist attacks. 

I read the paper with great interest. I appreciate the attempt to quantify the long-term effect of a real world phenomenon such as a terrorist attack, which is a complex and analytically demanding issue. Even though I’m not an expert in causal analysis, I definitely consider it to be a much needed approach, one that is unfortunately missing from the literature on political extremism. While I liked a lot about the paper, I have a few comments related to the issues of generalizability and specificity of the effect identified in the study. 

One strategy of inferring the causal effect in the study involved the use of multiple imputation. To that aim, the authors utilized data from the previous waves to impute the missing values for the condition that was not observed (i.e., a terrorist attack did not happen). While I understand the general logic of this strategy, I was wondering to what extent it was informative during this particular period of time, namely one that overlapped with the global pandemic. Specifically, I was wondering whether imputing values on the basis of relationships established before the attack (and before the pandemic) was appropriate strategy to predict attitudes toward Muslims in an alternative world in which attack did not happen (but the pandemic happened). I could imagine that the effects of some of the variables used for MI on attitudes could be different before and during the pandemic. Maybe the method used by the authors can address this problem but it would be good to clarify that. More generally, a more thorough discussion of the uniqueness of the period studied would be helpful. 


***This is a good point.  Muslim Acceptance during the following year may have been affected by the Global pandemic and New Zealand's severe COVID-19 lockdown. Indeed in the new analysis we find some evidence for diminished acceptance. The imputations in the Attack condition borrow from information both within persons and within waves.  The challenge comes to imputing responses in the no-attack condition. We have revised the manuscript to reflect that steady linear increase in the counterfactual no-attack condition presents a "worst case" scenario for regression to the mean. We focussed on presenting the "worst case" scenerio to avoid the interpretation that we have indeed recovered the counterfactual no-attack trend.**




My second question is related to the issue of variables used for MI. The authors write “To multiply impute missing values (k = −6 . . . 0, A|a = 0), we used baseline responses for Z = {age, education, ethnicity, has-partner, identity-male, is-employed, is-parent, NZ-deprivation, religious identification, resides-urban}..” However, I was not sure which wave the values of these variables were taken from (i.e., what does “baseline” refer to?). Does it mean that e.g. for a person who was low on NZ-deprivation in 2018/19 but high in 2020/21 the imputed value of their attitudes for 2021 will use their higher level of deprivation as the input? It would be good to clarify that. 


**In the original manuscript baseline is an individual's first observation in the study. We see this as doubly unclear. It is unclear for the reasons the reviewer emphasises. Each individual's baseline will differ. Additionally, we do not have a clearly defined target population. We address these issues by focussing on a single population, described as follows: ...."** 




Third, I was wondering whether the observed effect was specific to Muslims as a group targeted by the attack or it generalized across other groups as well. It could be that after the attack positivity of attitudes to other social groups increased as well (e.g., due to a desire for social cohesion). Given that participants rated their feelings toward several groups, a similar analysis using items measuring attitudes toward other groups could show whether the effect was unique to Muslims or not. If yes, this could strengthen the interpretation of the authors. One could expect that some of the groups could experience a decrease in positive attitudes after the attack. Again, if confirmed that could strengthen the interpretation. 


**Prejudice to other minorities: this is the topic of our next manuscript, where we investigate effects on prototypical and non-prototypical minorities. We considered focusing on all prejudice effects, however the resulting manuscript becomes unweildy. Our interest here is whether increased acceptance of the target community is short lived. Even under the "worst case" scenario we see that it was not short lived.  Additionally, the revised manuscript focuses on whether effects were modified depending on one's political orientation. This adds additional burdens on the audiences attention.  That sai, it is a good point to include negative controls. The revised manuscript includes the three non ethnic prejudice indicators, overweight people, mentally ill people, and the elderly, and finds no evidence for an attack affect.  We're grateful for the reviewers suggestion to include a negative control.**



More generally, given that the focus of the paper is on the causal analysis of the effect of the attack, a discussion of possible explanations and boundary conditions would be useful as it might suggest psychological mechanisms of this effect. For instance, it seems to me that it is not possible (?) to distinguish between the explanation that is focused on the occurrence of the attack and the explanation that attributes the effect to the responses to attack, which might be more specific to the socio-political context of New Zealand. It could be that it was something about the reaction to the attack (e.g., by politicians in NZ, etc.) that facilitated positive attitudes toward Muslims in society rather than the fact that this group was targeted in the attack. While the authors mention the issue of (limited) generality in the discussion I think it should be discussed more extensively. A minor comment: I would also suggest editing the title of the paper (“Long-term causal effect of radical white terrorism”) to be more specific as it currently suggests the level of generalizability that goes beyond the findings. 

**Another excellent point. Thank you. We have revised the manuscript as follows...**



Moreover, in the studied sample attitudes toward Muslims at the beginning of the study were just below the mid-point and they were becoming more positive over time. Should a similar effect be expected if the attitudes toward a group were more negative to begin with? How could different pre-existing norms change the perception of the attack (as more or less immoral) and as a consequence the perception of and attitudes toward the targeted group? I do not mean to question the importance of the study and the analyses, which I consider to be very useful and inspiring. I would just like to suggest developing the theoretical discussion of the results in a direction that might inspire more research on this topic. At this point, the theoretical interpretation of the obtained results is largely missing from the paper. 


**This is related to the previous points. It is a good comment.  We have revised the manuscript as follows...**




Reviewer #2 Comments for the Author: 

Dear authors, dear editors, 
I liked the paper in general. The research question is precise, the results are interesting and relevant. The methods are interesting as well and I like the use of graphical models to show the causal assumptions. Furthermore, I like the handling of panel attrition. 

However, I have one really big issue with the identification strategy. It could be that the authors are able to convince readers of their manuscript that their method is appropriate, this is why I recommend “revise and resubmit”. But I have serious doubts about whether the authors can fulfill their promise of estimating unbiased long-term trends in this empirical setting over and above what the shown regression discontinuity analysis can do. 

I think there is a confusion about what the imputation method is able to achieve. The imputation method is interesting, but in essence, it can only give us counterfactual trends if it adjusts for confounding. Note that also in the Westreich paper cited in the manuscript, Westreich et al. use imputation to adjust for confounding variables Z. 
So what are the relevant confounding variables in a setting where the treatment is assigned to a whole population (on a macro level) exogenously (individuals do not have control over it)? 



The authors rely on pre-attack trajectories of the outcome and stable individual-level variables to impute the counterfactual outcome that would have occurred if the attack did not happen. The problem is that these variables are not the relevant confounding variables that might bias our causal effect estimate in this setting. This is because individuals do not select (or are assigned) into the post-attack phase based on these variables. This is because the treatment in this study is something that happens independently of individual level factors (it is outside of individual control). Another way to put this is that the variables that the authors use for their imputation do not help to make the conditional exchangeability assumption more credible. 



The variables that might bias causal inference in a setting where the treatment is assigned on the macro level (and we are interested in long-term effects) are other time-varying macro conditions. For example, the effect one year after the attack might be confounded by the fact that the overall discourse on immigration changed (because of other reasons than the attack), because macro-economic conditions changed, or, maybe even another terrorist attack happened in the post-period etc. 
Now, usually we would deal with this type of confounding by comparing the treated country to another similar country; or individuals who were exposed to others who did not know of the terror attack. This would allow to control for period effects to some extent. 



**We agree with the skepticism, although for someone different reasons. The problem is not one of confounding or of treatment assignment. We see a problem. with model specification. Imputing a counterfactual outcome relies on strong assumptions.**


Of course, this is not possible with the data at hand. This is why a regression-discontinuity-in-time design (as presented in this analysis) focuses on the period directly before and directly after the attack. This is not a drawback of the method of regression discontinuity, but an essential limitation of the data available in research on the effects of terrorist attacks on one country. Again, controlling for or imputing based on individual level variables does nothing to adjust for these types of time-varying macro shocks (even if the models are as complex as the ones presented in the paper). That being said, it might be that the method could be used to model confounding macro shocks as well, and I am looking forward to the author’s response. 

Of course, it is technically true that the method allows us to estimate counterfactual trends “for responses that are never observed across the entire population” (p. 23), but what makes the authors believe that these trends are estimated correctly in this specific set-up? Since this imputation is based on pre-attack variables, the analysis assumes that everything stays constant after the attack (apart from a general time trend). These are very similar core assumptions as in a regression-discontinuity-in-time design (no shocks after treatment etc.). It is questionable whether counterfactual long-term trends can be meaningfully without a control group (a set of individuals who were not exposed or another country). 

A final remark about the language in the article. I think the causal terminology should be related more specifically to the setting of the study. E.g. what are the threats to the exchangeability assumption in this specific set-up? How does imputing based on individual level, pre-attack variables Z help with that etc. Why were these specific variables Z chosen and not others? 

All that being said, I like that the authors use a regression discontinuity design. In my opinion, this is the maximum of what can be done in the setting of this study (though I am looking forward to be convinced). 


Small remarks: 
- The term SWIG comes up, but is not explained (unlike DAGs, SWIGs might not be familiar to most readers) 



Reviewer #3 Comments for the Author: 

The paper investigates the influence of the 2019 Christchurch attack on feelings toward Muslims using panel data from the New Zealand Attitudes and Values Study and a potential outcomes framework. It reports a positive effect immediate effect as well as a positive trend in attitudes in the two years following the attack. With the sad increase in far-right terror attacks in Western societies in recent years, this is a topical question and the counterfactual approach is novel to this field. However, I think the paper would benefit from more theoretical depth. 

While the study uses elaborated modeling techniques, it remains purely descriptive in terms of theory. This might be because there is not much research on the impact of far-right terror attacks, but I would find it even more important in this case. Especially since existing studies do not all point in the same direction. Jakobsson & Blom (2011, cited in the manuscript) report that Norwegians’ attitudes toward immigrants were more positive after the terror attacks of Breivik. However, other research on anti-immigrant violence more broadly finds that such violence leads to attitudes that are more negative (Igarashi 2020). Eger & Olzak (forthcoming in IMR) argue that anti-refugee violence draws voters with anti-immigration dispositions to the far-right, but not those with pro-immigration views. Such nuances might help the authors to develop the theoretical mechanism that leads to the outcome found in this study. 

I commend the authors’ counterfactual approach to the identification of the causal effect of the attack. The authors correctly argue that these methods have hardly been applied in the literature on the impact of terror attacks on public opinion, which mostly use natural experimental designs. A lot of the information that helped me understand the method better was only part of the Supplementary Material. This might be specific for the format of this submission, but I would find it helpful if sections 6 and 7 of the annex would be included in the main text. 

Third, I was wondering about the framing of the finding. In the abstract, the authors write “We conclude that the post-attack acceptance effect of the targeted Muslim community following the 2019 Christchurch mosque attacks was durable for at least two years.” However, the study also shows that “this rate of growth in Muslim acceptance was roughly similar to the inferred rate of increase in Muslim acceptance had the attacks not occurred” (page 8). To what degree are the two interpretations conflicting? In my understanding, there seems to be an overall positive time trend in feelings toward Muslims that continued after the attack. In contrast to the short-term increase in acceptance, this trend is not driven by the attack as it would have occurred anyway. 
Related to this, the coefficients reported in the study are statistically significant but seem to be rather small (main effect of 0.19 and interaction of 0.05 on the 7-point scale). As a comparison, how much of the standard deviation of the outcome do the effects amount to? Are they comparable to the findings in prior research on, for example, the negative impact of Islamist attacks? 

The Feeling Thermometer on the survey includes various other groups, several of which should not be related to the attack (e.g. elderly people, people with a disability, overweight people). These groups could be used to test the excludability assumption, as we would not expect an effect on these outcomes (see point 4.3.3 in Muñoz, Falcó-Gimeno and Hernández 2019 in Political Analysis). 

Minor 
• I generally like the figures, but some of them could be even clearer. That is, the legend of Figures 1, 4, 13-16, 18-21 should be harmonized, and the x-axis of 4B. 
• The title uses “radical white terrorism” but this isn’t really defined in the paper. I’d suggest using “far-right terrorism”, which seems a more common term in the literature. 
